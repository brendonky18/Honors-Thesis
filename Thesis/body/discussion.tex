% Talk about how technical issues may have colored their perceptions of the difficulty

% Many students reported feeling lost or overwhelment (consistent with other research)

% "I think it is a great challenge, but I would make my instructions a bit more clear and give more examples when possible. more examples means less guessing and making wrong assumptions" => also consistent with research that students will learn wrong things

% Talk about how the technical problems could have been an issue

% Students complained about the time constraint
% Anecdotal: students frequently complain that professors fail to consider the other classes that they are taking, and a feeling that their class is exclusively entitled to their student's free time. 

% Unfortunately, with such a small data set, it's impossible to draw any statistically significant results. If we could extrapolate the current data onto a dataset 4 times as large, then we would could say that there is a significant relationship (Insert chi2) between the instruction set received and the student's success

% extrapolate data gives significant result
% this is a promising indication for future research
% While this is far from conclusive evidence, it is also more rigorous/scientific/data-driven than any existing research.

% % raw data
% $\chi^2(4, N=12)=3, p<0.56$
% % quadrupled dataset
% $\chi^2(4, N=48)=12, p<0.02$

% Beyond this, there are a number of improvements which could be made to designs of the experiment, activities, and instructions.
% 


% \subsubsection*{Overall Trends}
% The most obvious trend is that the respondents unanimously agree that reducing the amount of guidance provided would not improve the learning experience, and all but one believe that it would negatively impact their experience, with the one remaining student not saying so only because they found the instructions completely unhelpful.

% There is also a relationship between 

% relationship between time spent, progress made, and learning outcomes

% the realities of time constraints
\section{Utility of Hands-On Activities}
    The results of these experiments overwhelmingly confirm the long-standing wisdom that hands-on activities are an effective way to teach. 
    All of the students responded that in general, hands-on activities are useful for learning new material. 
    Despite the various problems they encountered, students also broadly had positive things to say about the two activities that they worked on. 
    Of the complaints that were given, students had three primary grievances:
    \begin{itemize}
        \item The amount of time given to work on the activities was insufficient.
        \item The provided instructions gave an insufficient amount of guidance.
        \item The presence of technical issues that hampered their ability to make progress.
    \end{itemize}
    The complaints about technical issues are inherent to the design of the activity, and there is much room for improvement should this be revisited in the future. 
    These issues notwithstanding, the other two complaints clearly corroborate the research of \citeauthor{J-Sweller}. 
    
    Perhaps rather obviously, several students included time as a consideration. 
    A frequent response when asked about receiving less guidance, is that the activity would have taken more time to complete. 
    Several students also commented that they already didn't have enough time to work on the activities. 
    In the literature, time spent working is also a common topic of discussion and inquiry. 
    As \textcite{C-Linehan} mentions, time spent engaged in learning is a strong predictor of student success. 
    However, not all of this time is equally as productive or valuable. 
    In their research, \textcite{Z-Zeng} finds a clear distinction between time spent reading materials, and time spent actively working on an activity. 
    In their environment, they find that time spent reading strongly correlates with time spent working on a lab in addition to better learning outcomes. 
    The same cannot be said for time spent working on a lab activity, while there was a correlation found between time spent working, and learning outcomes, the correlation was notably weaker. 
    
    In our case, if we reduce the amount of guidance provided by the instructions, it can reasonably be inferred that students will then spend less time reading those instructions. 
    Therefore we must assume that when students refer to an increased amount of time, they are referring to time that will be spent working on the activity. 

\section{Comparing Activities}
    In their paper, \citeauthor{R-Weiss} remarked that perhaps different approaches to designing hands-on activities are warranted when addressing different kinds of learning. 
    They theorize that more explicit direction is most effective when trying to impart \say{content knowledge}, but that less direction is more appropriate if the aim is to teach \say{skills or abilities}. 
    The results of this experiment cannot corroborate this notion. 
    In both activities, the most common complaint was the lack of guidance provided. 
    
    \subsection{Learning Outcomes}

        \subsubsection*{Crypto Cracking}
            In the case of the content-based crypto cracking activity, a chi-square test of independence was performed to determine whether there was a relationship between the level of guidance received, and the learning outcomes in regards to their practical knowledge. 
            It found that there was a significant relationship between the two $(\chi^2(2, N=11)=7.975,  p = 0.01855)$. 
            Those who received more explicit instructions learned more. 
            \emph{See Table~\ref{tab:cc-pLO-v-g}.}

            \begin{table}
            \begin{center}
                \begin{tabular}{|c|c|c|c|}
                    \hline
                        & Not Improved & Slightly Improved & Greatly Improved \\
                    \hline
                    Min. Guidance & 0 & 4 & 0\\
                    \hline
                    Int. Guidance & 0 & 1 & 3\\
                    \hline
                    Max. Guidance & 0 & 1 & 2\\
                    \hline
                \end{tabular}

                \caption{Crypto Cracking practical learning outcomes vs. guidance}\label{tab:cc-pLO-v-g}
            \end{center}
            \end{table}

        \subsubsection*{Going Backwards}
            When examining the skills-based \emph{going backwards} activity, we perform the same test. 
            If there is a negative relationship between guidance and learning outcomes, like was suggested \cite{R-Weiss}, then there should be a similarly strong association between the two variables. 
            Instead, the relationship is much weaker $(\chi^2(4, N=12)=7.5,  p = 0.1117)$, suggesting that this is not the case. 
            \emph{See Table~\ref{tab:gb-LO-v-g}.} 

            \begin{table}
            \begin{center}
                \begin{tabular}{|c|c|c|c|}
                    \hline
                        & Not Improved & Slightly Improved & Greatly Improved \\
                    \hline
                    Min. Guidance & 3 & 0 & 1\\
                    \hline
                    Int. Guidance & 0 & 3 & 1\\
                    \hline
                    Max. Guidance & 1 & 1 & 2\\
                    \hline
                \end{tabular}

                \caption{Going Backwards learning outcomes vs. guidance}\label{tab:gb-LO-v-g}
            \end{center}
            \end{table}

        However, it may not be entirely fair to make a direct comparison between these two. 
        In the case of \emph{going backwards}, all students had some previous knowledge of RSA, but with reverse engineering, only a handful of students had any prior knowledge. 
        Perhaps, this imbalance in knowledge can account for the weaker association. 
        In this case, it may be more fair to examine the theoretical learning outcomes of the \emph{crypto cracking} activity. 
        While all\footnote{Barring the previously noted exception.} students had previously learned about RSA to some extent, only a small number said that they had knowledge of the underlying mathematics ---
        in the same way that only a few students have experience applying the skill of reverse engineering. 
        If we perform a chi-square test of independence between the level of guidance and the theoretical learning outcomes, we see there is a comparably weak relationship $(\chi^2(4, N=12)=6,  p = 0.1991)$. 
        \emph{See Table~\ref{tab:cc-tLO-v-g}.}

        \begin{table}
        \begin{center}
            \begin{tabular}{|c|c|c|c|}
                \hline
                    & Not Improved & Slightly Improved & Greatly Improved \\
                \hline
                Min. Guidance & 1 & 2 & 1\\
                \hline
                Int. Guidance & 3 & 0 & 1\\
                \hline
                Max. Guidance & 0 & 1 & 2\\
                \hline
            \end{tabular}

            \caption{Crypto Cracking theoretical learning outcomes vs. guidance}\label{tab:cc-tLO-v-g}
        \end{center}
        \end{table}

        This suggests that previous experience might explain why we don't see a comparably strong relationship. 
        If this is the case, then we might expect a strong correlation between experience and learning outcome for both; 
        as it turns out, this is also not the case. 
        There is some relationship between previous theoretical understanding of RSA, and learning outcomes $(\chi^2(2, N=11)\approx4.519,  p = 0.1045)$, but the same cannot be said for previous experience with reverse engineering and learning outcomes $(\chi^2(2, N=11)\approx1.637,  p = 0.4411)$. 
        This difference could have a number of explanations. 
        Most obviously, these are two fundamentally different kinds of knowledge, and learning outcomes may be affected by prior knowledge differently. 
        When dealing with a concrete subject such as RSA, there is an upper limit on how much one can possibly know. 
        If one completely understands the proofs and underlying mathematics, then there is nothing left to learn. 
        Conversely, with a skill, such as reverse engineering, there is no equivalent for this hard upper limit. 
        In regards to a skill, it is always possible to learn new techniques, have more practice, and gain more experience. 

        In order to conduct a fair comparison, we would have to control for each participant's knowledge in areas related to the activities. 
        This is an straightforward next step however, because the sample is so small, controlling for these variables results in a dataset that is too small to produce any statistically significant result. 
        While we can reasonably assert that increased guidance has a positive effect on practical learning outcomes in regards to content-based knowledge such as RSA, the evidence is less conclusive in regards to skill-based learning. 

        % level of instruction <-> time spent better elsewhere?

    \section{Instructor Access}
        Out of all the factors measured in the survey, above all else, the greatest indicator of success was instructor access. 
        In the crypto cracking activity, 4 students had contacted the instructor (myself). 
        Of these 4 students, 50\% were able to complete the activity, and 75\% were able to complete at least the first task. 
        Furthermore, they also spent more time on the activity, compared to those without instructor access. 
        Individually, this group spent between 6 to 10 hours, on average they spent 8 hours each working on the activity. 
        This group also had the best learning outcomes. 
        The entire group experienced \emph{great} improvement in their practical understanding of RSA, and 50\% \emph{greatly} improved their theoretical understanding of RSA.

        The students without access to the instructor fared much poorer across all three categories. 
        In this group, only 12.5\% completed the entire activity, and only 37.5\% made any kind of progress. 
        The spent 1 to 7 hours on this activity, working on it for an average of 3.125 hours each --- 
        less than half the amount of time compared to the other group. 
        Finally, only 12.5\% greatly improved their practical knowledge of RSA, and only 25\% greatly improved their theoretical knowledge. 

        Superficially, this comparison would seem to offer resounding support for the intermediate guidance approach. 
        However inspecting the student feedback allows us to make a different inference. 
        In contacting the instructor, all 4 student's questions involved technical problems caused by the implementation of the activity, rather than questions about problem-solving. 
        Furthermore, students frequently complained about being frustrated by these same technical issues in their feedback. 
        This is a problem with the design of the experiment itself, and unfortunately it is impossible to control for this in our data set as it effected every participant. 

\section{Practical Considerations}
    While it serves well to discuss these activities in the abstract, there are also practical considerations which must be made. 
    
    \subsection{Rate of Completion}
        Given that these activities are intended for educational purposes, they will naturally be included as some kind of course work.
        For this to occur, there must be some kind of grading scheme, and in all likelihood, that grading will depend on a student's completion of the activity. 
        These activities should be designed such that all the information is imparted through completing the activity. 
        If an activity requires a student to go out of their way to search for some non-obvious piece of information, it's unreasonable to assume that every student will be able to find this information independently. 
        On the other hand, if all of the information is front-loaded such that the student doesn't need to actually work on the activity to glean all of the necessary information, then the activity is a waste of their time. 

        %  analyze how guidance impacts rate of completion, and how RoC impacts LO

    \subsection{Time Spent}
        Another serious consideration when incorporating these activities into an educational environment is the amount of time required to work on these activities. 
        While some university professors may operate under the notion that they are entitled to the entirety of a student's time, this is obviously an unrealistic expectation. 
        When assigning an activity, students should be able to complete it within a reasonable amount of time. 
        
        As was demonstrated by \citeauthor{C-Linehan} and \citeauthor{Z-Zeng}, the amount of time a student spends actively engaged in learning is strongly associated with learning outcomes. 
        The results of this experiment can corroborate this. 
        A one-way ANOVA confirmed that the amount of time a student spent on an activity, has a significant impact on their learning outcomes overall $[F(2,31)=12.399, p=0.0001]$.
        
        When broken down into each of the three observed learning outcomes 
        (practical knowledge of RSA, theoretical knowledge of RSA, and understanding of reverse engineering),
        we also find there is a correlation, albeit not as strong. 
        In regards to their practical knowledge of RSA, time spent had a strong impact $[F(1,9)=33.965, p<0.001]$. 
        When the same test was performed between time spent, and theoretical knowledge, a much weaker relationship was found $[F(2, 9)=2.040, p=0.186]$. 
        This corroborates the earlier finding, that theoretical knowledge learning outcomes more closely is associated with previous knowledge. 
        However, this was not as strongly demonstrated for learning outcomes for reverse engineering. 
        Once again, an one-way ANOVA between time spent, and reverse engineering learning outcome found a similar result $[F(2, 7)=2.183, p=0.183]$. 

        When broken down into its constituent components, the relationship may not be as strong.
        In spite of this, it is clear that overall, time spent is a reliable indicator of learning outcomes.

        We can be confident that the reported time is a fair reflection of the time they spent actively learning, because completion of this assignment was not mandatory. 
        All participants were reminded several times that if they could not make progress --- 
        i.e. they were not learning anything --- then they should stop working on it. 
        Therefore, this time is a measurement of how long each student was working productively towards the goal. 

        Owing to the fact that completion was optional, students were afforded the ability to give up part of the way through. 
        However, in the case where such an assignment is a required part of a course, completion will likely be required to receive the highest grade. 
        In this case, students who were unable to complete the assignment are likely to spend much more time, incentivized by their desire to maintain good academic standing. 
        As \citeauthor{Z-Zeng} demonstrated, not all time is made equal. 
        Any additional amount of time a student would have spent after the point which they gave up is likely to be far less productive as far as learning is concerned. 
        Rather than working productively towards the solution, these students will be spending a large portion of that time trying to learn what they should be learning.

        % show relationship between time spent and LO
        % This was optional, the measured time can be seen as a reflection of how much time a student was working productively towards the goal. 
        % If it were required as an assignment, then students would be spending more time, but not spending it learning effectively.
        % This demonstrates both Zeng and Linehan's points about time. 

    \subsection{Unintended Solutions}
        Activities are ideally designed such that learning occurs at every stage of the process. 
        If students are not given any guidance, then they could very easily find solutions that technically produce the correct results, but in an unintended manner. 
        Unfortunately for the instructor, this also means that they will be bypassing part of the intended learning process. 
        Providing maximal guidance mitigates this possibility in two ways. 
        First, it codifies a canonical \emph{intended solution}, such that students are aware of how they are supposed to approach a problem. 
        This mitigates the possibility that a student accidentally or inadvertently discovers a workaround to the activity. 
        Secondly, providing explicit instructions ensures that the intended path to completing the activity is also the path of least resistance. 
        Should students become stuck or frustrated by their inability to make any progress, they may attempt to find a simpler solution which allows them to \emph{cheat}. 

    % \subsection{Maintains Motivation}
    %     Much like how people like to have progress bars, even though they are meaningless in many instances, students like to know how much work is expected of them. 

    % LoG <-> student preferences


        

